{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Satellite Environment with OpenAI Gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gym\n",
      "  Using cached gym-0.26.2.tar.gz (721 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in c:\\users\\ricky\\miniconda3\\lib\\site-packages (from gym) (4.8.1)\n",
      "Collecting gym-notices>=0.0.4\n",
      "  Using cached gym_notices-0.0.8-py3-none-any.whl (3.0 kB)\n",
      "Collecting cloudpickle>=1.2.0\n",
      "  Using cached cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\ricky\\miniconda3\\lib\\site-packages (from gym) (1.21.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\ricky\\miniconda3\\lib\\site-packages (from importlib-metadata>=4.8.0->gym) (3.6.0)\n",
      "Building wheels for collected packages: gym\n",
      "  Building wheel for gym (PEP 517): started\n",
      "  Building wheel for gym (PEP 517): finished with status 'done'\n",
      "  Created wheel for gym: filename=gym-0.26.2-py3-none-any.whl size=827648 sha256=e579bdb4cc7dbe62251e7a71ca32dd6375ea276092dce2c088d073ad8171d564\n",
      "  Stored in directory: c:\\users\\ricky\\appdata\\local\\pip\\cache\\wheels\\17\\79\\65\\7afedc162d858b02708a3b8f7a6dd5b1000dcd5b0f894f7cc1\n",
      "Successfully built gym\n",
      "Installing collected packages: gym-notices, cloudpickle, gym\n",
      "Successfully installed cloudpickle-2.2.1 gym-0.26.2 gym-notices-0.0.8\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym import Env\n",
    "from gym.spaces import *\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "State of satellite\n",
    "P: power of satellite\n",
    "S1: memory in sensor 1\n",
    "S2: memory in sensor 2\n",
    "S3: memory in sensor 3\n",
    "E: electronics of satellite\n",
    "O: orbital motion of satellite\n",
    "T: time of the day-> ionosphere behavior\n",
    "\n",
    "State Space:\n",
    "S = (P, S1, S2, S3, E, O, T)\n",
    "P = {100, 99, 98, …, 3, 2, 1, 0}\n",
    "S1 = {100, 99, 98, …, 3, 2, 1, 0}\n",
    "S2 = {100, 99, 98, …, 3, 2, 1, 0}\n",
    "S3 = {100, 99, 98, …, 3, 2, 1, 0}\n",
    "E = {0, 1} not working / working\n",
    "O = {0, 1} not in range / in range\n",
    "T = {0, 1, 2, 3, 4} night, dawn, morning, afternoon, dusk\n",
    "\n",
    "Action Space:\n",
    "A = {transmit, not transmit} = {1, 0}\n",
    "\n",
    "Step Function:\n",
    "*If a1= transmit = 1, then:\n",
    "    P(state=s) transitions to a lower value P(state=s’) ---> power discharges\n",
    "    Ex: P=100 -> a1 (transmit) -> P=95\n",
    "    S1(state=s) transitions to a lower value S1(state=s’) ---> free memory in sensor 1 decreases (data transferred)\n",
    "    Ex: S1=100 -> a1 (transmit) -> S1=96.5\n",
    "\n",
    "*If a1= not transmit = 0, then:\n",
    "    P(state=s) transitions to a higher value P(state=s’) ---> power charges\n",
    "    Ex: P=70 -> a1 (not transmit) -> P=73\n",
    "    S1(state=s) remains the same S1(state=s’) ---> free memory in sensor 1 constant (no data transferred)\n",
    "    Ex: S1=70 -> a1 (not transmit) -> S1=70\n",
    "\n",
    "Reward:\n",
    "*If a1=1 (transmit), then:    ---> For each transmission we get reward\n",
    "    reward +=5 \n",
    "*If P(state=s’)>=30, then:    ---> Rewards for maintaining power more than 30%\n",
    "    reward +=2 \n",
    "*If we transmit all the data within the time satellite is within range then:\n",
    "    reward += 5*(remaining time for satellite in range)  --->More rewards for quicker transmission\n",
    "\n",
    "Termination:\n",
    "An action can occur every minute for an hour (when the satellite is within range) or until the sensor memory is full i.e. terminate if:\n",
    "*S1(state=s) = 0 --->Transmission complete\n",
    "*O(state=s) = 0  --->Satellite out of range\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "class SatelliteEnv(Env):\n",
    "    def __init__(self):\n",
    "        # A = {transmit, not transmit} = {1, 0}\n",
    "        self.action_space = Discrete(2)\n",
    "        # S = (P, S1, S2, S3, E, O, T)\n",
    "        #Note currently only using P,S1,O\n",
    "        self.observation_space = Tuple((Box(0, 100, shape=(4,)),MultiDiscrete([ 2, 2, 5 ])))\n",
    "        # Set start states\n",
    "        self.state = np.zeros(7)\n",
    "        for i in range(7): \n",
    "            if i<4:\n",
    "                self.state[i] = 100\n",
    "            elif i<6:\n",
    "                self.state[i] = 1\n",
    "            else:\n",
    "                self.state[i] = 2\n",
    "        \n",
    "        #Transmission Time 60 mins\n",
    "        self.transmission_time = 60\n",
    "        \n",
    "    def step(self, action):\n",
    "        #A = {transmit, not transmit} = {1, 0}\n",
    "        #Update States\n",
    "\n",
    "        if self.state[0]>=5: #no action 1 if P < 5 \n",
    "            if action==1:\n",
    "                self.state[0] += -5   #discharging\n",
    "                self.state[1] += -3.5 #update free memory\n",
    "        if action==0:\n",
    "            self.state[0] += +3 #charging\n",
    "            \n",
    "        #Check States within bounds\n",
    "        for i in range(2):\n",
    "            if self.state[i]>100:\n",
    "                self.state[i] = 100  \n",
    "            elif self.state[i]<0:\n",
    "                self.state[i] = 0\n",
    "             \n",
    "        # Reduce transmission time by 1 minute\n",
    "        self.transmission_time -= 1\n",
    "        \n",
    "        # Calculate reward\n",
    "        reward = 0\n",
    "        if self.state[0]>=30:\n",
    "            reward += 2\n",
    "        else: \n",
    "            reward += 0\n",
    "        if action==1:\n",
    "            reward += 5\n",
    "        if self.state[1]==0:\n",
    "            reward += (60 - self.transmission_time)*5\n",
    "        \n",
    "        # Check if transmission time is done\n",
    "        if self.transmission_time <= 0:\n",
    "            self.state[5] = 0\n",
    "    \n",
    "        if 0 in self.state[[1,5]]:\n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "        \n",
    "        # Set placeholder for info\n",
    "        info = {}\n",
    "        \n",
    "        # Return step information\n",
    "        return self.state, reward, done, info\n",
    "\n",
    "    def render(self):\n",
    "        # Implement viz\n",
    "        pass\n",
    "    \n",
    "    def reset(self):\n",
    "        # Reset states\n",
    "        self.state = np.zeros(7)\n",
    "        for i in range(7): \n",
    "            if i<4:\n",
    "                self.state[i] = 100 #random.randint(90,100)\n",
    "            elif i<6:\n",
    "                self.state[i] = 1\n",
    "            else:\n",
    "                self.state[i] = 2\n",
    "        # Reset time\n",
    "        self.transmission_time = 60 \n",
    "        return self.state\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = SatelliteEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([54.253082 , 28.48446  , 94.80227  ,  1.0961682], dtype=float32),\n",
       " array([1, 1, 4], dtype=int64))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  1   Score:455.0   Transmissions:  29   Total Time:  50   Final States(P,S,O):  12.0,   0.0,   1.0\n",
      "Episode:  2   Score:245.0   Transmissions:  25   Total Time:  60   Final States(P,S,O):  71.0,  12.5,   0.0\n",
      "Episode:  3   Score:554.0   Transmissions:  29   Total Time:  59   Final States(P,S,O):  41.0,   0.0,   1.0\n",
      "Episode:  4   Score:558.0   Transmissions:  29   Total Time:  59   Final States(P,S,O):  41.0,   0.0,   1.0\n",
      "Episode:  5   Score:551.0   Transmissions:  29   Total Time:  58   Final States(P,S,O):  42.0,   0.0,   1.0\n",
      "Episode:  6   Score:565.0   Transmissions:  29   Total Time:  60   Final States(P,S,O):  48.0,   0.0,   0.0\n",
      "Episode:  7   Score:522.0   Transmissions:  37   Total Time:  55   Final States(P,S,O):   2.0,   0.0,   1.0\n",
      "Episode:  8   Score:450.0   Transmissions:  29   Total Time:  47   Final States(P,S,O):   3.0,   0.0,   1.0\n",
      "Episode:  9   Score:544.0   Transmissions:  29   Total Time:  57   Final States(P,S,O):  36.0,   0.0,   1.0\n",
      "Episode: 10   Score:260.0   Transmissions:  28   Total Time:  60   Final States(P,S,O):  53.0,   2.0,   0.0\n"
     ]
    }
   ],
   "source": [
    "episodes = 10\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0 \n",
    "    a=[]\n",
    "    \n",
    "    \n",
    "    while not done:\n",
    "        #env.render()\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        a.append(action)\n",
    "        score+=reward\n",
    "    out_states = ','.join(map('{:6}'.format, n_state[[0,1,5]]))\n",
    "    print('Episode:{0:3}   Score:{1:5,.1f}   Transmissions:{2:4}   Total Time:{3:4}   Final States(P,S,O):{4:5}'.format(episode,score,a.count(1),np.size(a),out_states))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
